[["index.html", "Series de Tiempo - Volatilidad Precio Bitcoin Capítulo 1 Propuesta Bookdown", " Series de Tiempo - Volatilidad Precio Bitcoin Christian Daniel Escobar Anduquia Luis Carlos Ruiz Ramos Daniel Felipe Duarte Quintero 2024-12-05 Capítulo 1 Propuesta Bookdown El tipo de información para analizar corresponde al precio del Bitcoin. Para ello, se llevará a cabo un estudio centrado en su comportamiento a lo largo del tiempo, con especial atención en identificar si presenta los componentes típicos de una serie de tiempo, como la tendencia, estacionalidad, ciclos, entre otros. El análisis de series de tiempo es esencial, dado que permite evaluar si el comportamiento pasado de una variable tiene relación con su evolución futura, algo crucial al estudiar activos financieros tan volátiles como el Bitcoin. El Bitcoin, como criptomoneda, ha ganado relevancia en los mercados financieros gracias a su naturaleza descentralizada, su capacidad para diversificar portafolios y su marcada volatilidad. Aunque esta volatilidad puede percibirse como riesgosa, también ofrece oportunidades de alta rentabilidad para aquellos inversionistas con una menor aversión al riesgo, que buscan aprovechar fluctuaciones rápidas y significativas en su precio. La importancia de determinar si el precio del Bitcoin cumple con los componentes de una serie de tiempo, radica en la capacidad de realizar predicciones más precisas sobre su comportamiento futuro. Identificar una tendencia o ciclos repetitivos permitiría a los inversionistas tomar decisiones informadas sobre el mejor momento para comprar o vender este activo, lo que podría maximizar sus rendimientos y minimizar riesgos. La predicción del precio del Bitcoin no solo es relevante para los inversionistas individuales, sino también para quienes gestionan portafolios diversificados o desean establecer mecanismos de cobertura frente a la volatilidad del mercado. Con una adecuada predicción basada en series de tiempo, que combine tanto el análisis técnico como el fundamental, es posible desarrollar estrategias de inversión más robustas. Esto permitiría ajustar las decisiones de inversión de acuerdo con los movimientos del Bitcoin en relación con otros activos financieros, detectando períodos óptimos para comprar o vender. Las series de tiempo también permiten evaluar cómo la volatilidad del Bitcoin se correlaciona con otros activos, proporcionando a los gestores de portafolios herramientas para optimizar la diversificación y desarrollar mecanismos de cobertura que mitiguen el riesgo asociado a las fluctuaciones de este criptoactivo. Para alcanzar este objetivo, se emplearán datos diarios que incluyan, entre otras variables, el precio de cierre del Bitcoin. Estos datos se obtendrán de Yahoo Finance, una fuente confiable y ampliamente reconocida que ofrece información precisa y actualizada sobre los precios de diversos activos financieros, incluidas las criptomonedas. Yahoo Finance se destaca por su accesibilidad y la calidad de sus datos históricos, lo que permite realizar análisis detallados y a largo plazo sobre el comportamiento del precio del Bitcoin. Los datos se pueden consultar en: https://finance.yahoo.com/quote/BTC-USD/ Extraer Información desde Yahoo Finance # Obtener los datos de Bitcoin desde Yahoo Finance suppressWarnings(getSymbols(&quot;BTC-USD&quot;, src = &quot;yahoo&quot;)) ## [1] &quot;BTC-USD&quot; # Se almacenan en una variable llamada btc_data btc_data &lt;- suppressWarnings(getSymbols(&quot;BTC-USD&quot;, src = &quot;yahoo&quot;, auto.assign = FALSE)) # Se verifica la estructura del objeto str(btc_data) ## An xts object on 2014-09-17 / 2024-12-05 containing: ## Data: double [3733, 6] ## Columns: BTC-USD.Open, BTC-USD.High, BTC-USD.Low, BTC-USD.Close, BTC-USD.Volume ... with 1 more column ## Index: Date [3733] (TZ: &quot;UTC&quot;) ## xts Attributes: ## $ src : chr &quot;yahoo&quot; ## $ updated: POSIXct[1:1], format: &quot;2024-12-05 21:58:40&quot; En esencia los datos corresponden a observaciones de los valores de apertura, máximo, mínimo y cierre de Bitcoin (BTC-USD), junto con el volumen y el ajuste diario del mercado, iniciando en septiembre del 2014 y continuando hasta la fecha. # Generar primera fila first_row &lt;- head(btc_data, 1) # Mostrar la primera fila first_row ## BTC-USD.Open BTC-USD.High BTC-USD.Low BTC-USD.Close BTC-USD.Volume BTC-USD.Adjusted ## 2014-09-17 465.864 468.174 452.422 457.334 21056800 457.334 Se observa que, para el primer registro de negociación proporcionado de Bitcoin, hubo una volatilidad importante, con una diferencia de más de 15 USD entre el precio máximo y el mínimo. # Fila de referencia como última fila specific_row &lt;- btc_data[&quot;2024-12-01&quot;] print(specific_row) ## BTC-USD.Open BTC-USD.High BTC-USD.Low BTC-USD.Close BTC-USD.Volume BTC-USD.Adjusted ## 2024-12-01 96461.34 97888.12 95770.19 97279.79 36590695296 97279.79 En 2024, el precio de Bitcoin ha aumentado drásticamente, llegando a negociarse alrededor de los 100,000 USD. Esto representa un aumento masivo en su valor, lo que refleja la adopción y crecimiento de la criptomoneda a lo largo de los años. "],["estructura-de-datos.html", "Capítulo 2 Estructura de datos 2.1 Promedio Móvil 2.2 Rezagos (Lag) 2.3 Estacionalidad", " Capítulo 2 Estructura de datos Precio Ajustado de Bitcoin: Se define como el valor de cierre de Bitcoin en el mercado al final de cada día, ajustado por eventos de mercado que puedan afectar su valor, tales como cambios significativos en la estructura del mercado o alteraciones en la metodología de cálculo. En este caso, el precio ajustado proporciona una representación consistente del valor real de Bitcoin, reflejando no solo su cotización diaria sino también ajustes realizados por las plataformas de datos financieros. Estos ajustes eliminan efectos externos para facilitar un análisis temporal más preciso. En adelante esta variable se conocerá como “Precio” y estará expresada en dólares (USD). Para evaluar la estructura de la serie de tiempo, se grafica la variable Precio a lo largo del tiempo, con el objetivo de identificar posibles patrones visuales que ayuden a determinar el intervalo temporal más adecuado para explicar los componentes de la serie. # Graficar el precio usando la función base de plot plot(Cl(btc_data), main = &quot;Precio de Bitcoin&quot;, xlab = &quot;Fecha&quot;, ylab = &quot;Precio (USD)&quot;, col = &quot;blue&quot;) Entre septiembre de 2014 hasta diciembre de 2024 se observa una serie de fluctuaciones significativas en el precio del Bitcoin. Esta gráfica es un claro ejemplo de la volatilidad del mercado de criptomonedas, donde factores como regulaciones, adopción tecnológica, y cambios en el interés de los inversores pueden influir significativamente en el precio. En vista de lo anterior, se procede a dividir la serie en tres periodos para observar el comportamiento del precio. # Filtrar los datos por los tres periodos btc_2014_2018 &lt;- btc_data[&quot;2014-01-01/2018-12-31&quot;] btc_2018_2021 &lt;- btc_data[&quot;2018-01-01/2021-12-31&quot;] btc_2021_2024 &lt;- btc_data[&quot;2021-01-01/2024-12-01&quot;] # Graficar los tres periodos par(mfrow = c(3, 1)) # Configura la gráfica para que muestre 3 gráficos verticalmente # Graficar el periodo 2014-2018 plot(Cl(btc_2014_2018), main = &quot;Precio de Bitcoin (2014-2018)&quot;, xlab = &quot;Fecha&quot;, ylab = &quot;Precio (USD)&quot;, col = &quot;yellow&quot;) # Graficar el periodo 2018-2021 plot(Cl(btc_2018_2021), main = &quot;Precio de Bitcoin (2018-2021)&quot;, xlab = &quot;Fecha&quot;, ylab = &quot;Precio (USD)&quot;, col = &quot;green&quot;) # Graficar el periodo 2021-2024 plot(Cl(btc_2021_2024), main = &quot;Precio de Bitcoin (2021-2024)&quot;, xlab = &quot;Fecha&quot;, ylab = &quot;Precio (USD)&quot;, col = &quot;red&quot;) Se encuentra que el periodo más adecuado para analizar en detalle la serie de tiempo es el que comprende los años 2021 a 2024, debido a que presenta una combinación favorable de estabilidad relativa, menor volatilidad y relevancia temporal, que son factores clave para un modelado adecuado de series de tiempo. Adicional, al ser el periodo más reciente, refleja mejor las condiciones actuales del mercado. 2.1 Promedio Móvil El promedio móvil suaviza la serie para eliminar fluctuaciones cortas y destacar las tendencias a largo plazo. Se trabajará con la serie al corte del 01 de diciembre de 2024. # Extraer el Precio Ajustado btc_final &lt;- Ad(btc_data)[&quot;2021-01-01/2024-12-01&quot;] # Mostrar primeros registros head(btc_final) ## BTC-USD.Adjusted ## 2021-01-01 29374.15 ## 2021-01-02 32127.27 ## 2021-01-03 32782.02 ## 2021-01-04 31971.91 ## 2021-01-05 33992.43 ## 2021-01-06 36824.36 # Mostrar última fila para verificar el límite final de la serie tail(btc_final) ## BTC-USD.Adjusted ## 2024-11-26 91985.32 ## 2024-11-27 95962.53 ## 2024-11-28 95652.47 ## 2024-11-29 97461.52 ## 2024-11-30 96449.05 ## 2024-12-01 97279.79 lines(btc_ma, col = &quot;red&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Precio real&quot;, &quot;Promedio Móvil (30 días)&quot;), col = c(&quot;blue&quot;, &quot;red&quot;), lty = 1, lwd = 2, cex = 0.8) El promedio móvil proporciona una mejor percepción de la tendencia a largo plazo. Cuando el precio del Bitcoin está por encima de su promedio móvil, indica una tendencia alcista general, y cuando está por debajo, una tendencia bajista. En este caso se destacan los siguientes patrones: El precio de Bitcoin muestra una alta volatilidad a lo largo del período, con picos y caídas abruptas, siendo característico del mercado de criptomonedas, donde los precios pueden cambiar dramáticamente en cortos períodos de tiempo. Hay períodos claros donde el precio aumenta o disminuye de manera sostenida. Por ejemplo, un aumento significativo ocurre a principios de 2023, seguido de una caída y luego una recuperación hacia fines de 2023 y 2024. En otras palabras se observan tendencias tanto alcistas como bajistas. 2.2 Rezagos (Lag) El análisis de rezagos ayuda a ver la relación entre los valores pasados y actuales de la serie. # Gráfico de rezagos semanales (7 días) lag.plot(btc_final, lags = 7, do.lines = FALSE, main = &quot;Gráfico de Rezagos (7 rezagos semanales) para Bitcoin&quot;) Cada subgráfico muestra la relación entre el precio ajustado de Bitcoin en una semana dada y su precio en semanas anteriores (desde 1 semana atrás hasta 7 semanas atrás). Cada uno muestra una relación lineal positiva fuerte. Esto sugiere que los precios no son aleatorios; sino que, hay una consistencia o patrón predecible donde los precios de semanas anteriores tienen una correlación positiva con los precios futuros. Este comportamiento identificable es un indicativo de autocorrelación en la serie de tiempo, que es típica en datos financieros y económicos donde los valores pasados influyen en los valores futuros. Esto es un indicio para corroborar la hipótesis de que los precios de Bitcoin no son aleatorios, y en su lugar sugiere un modelo donde los precios siguen un patrón dependiente del tiempo. # Graficar la función de autocorrelación (ACF) acf((btc_final), main = &quot;Función de Autocorrelación (ACF)&quot;) Se observa que la autocorrelación se mantiene alta y positiva para cada rezago, disminuyendo gradualmente pero manteniéndose significativa a lo largo de los 30 rezagos observados. Esto refuerza la idea de que el precio de Bitcoin tiene una memoria de largo plazo, donde los valores pasados tienen una influencia prolongada sobre los valores futuros. # Graficar la función de autocorrelación autocorrelación parcial (PACF) pacf((btc_final), main = &quot;Función de Autocorrelación Parcial (PACF)&quot;) La autocorrelación parcial es significativa solo en el primer rezago y se acerca a cero en los siguientes rezagos, lo que indica que hay una relación importante entre el valor actual y el valor del periodo inmediatamente anterior, y que una vez se ha tenido en cuenta el efecto del valor de la semana pasada, los valores de semanas más remotas no añaden información relevante para predecir el valor actual. Esto sugiere que el impacto predictivo disminuye rápidamente después del primer rezago. En vista de lo anterior, el comportamiento de Bitcoin muestra una fuerte persistencia temporal, indicando que los precios pasados son muy útiles para predecir precios futuros a corto plazo. 2.3 Estacionalidad Descomponer la serie temporal en tres componentes: tendencia, estacionalidad y residuos, permite identificar ciclos recurrentes. # Convertir el xts a un objeto ts para la descomposición btc_ts &lt;- ts(as.numeric(btc_final), start = c(2021, 1), frequency = 365) # Aplicar la descomposición STL stl_result &lt;- stl(btc_ts, s.window = &quot;periodic&quot;) # Graficar la descomposición STL plot(stl_result) En el gráfico anterior se puede apreciar que: La estacionalidad (seasonal) muestra patrones recurrentes que se repiten a intervalos regulares. En este caso, parece haber una periodicidad anual, lo que indica que la amplitud de esta componente se mantiene relativamente estable. Hay presencia de tendencia (trend) de la serie, destacando una caída en la tendencia durante 2022, seguida por una recuperación gradual que empieza a aumentar hacia el final de 2023 y continúa en 2024. Esto indica que, a pesar de las fluctuaciones de corto plazo, hubo un período de descenso prolongado que luego se revirtió, sugiriendo una mejora en la valoración de Bitcoin. El componente residual (remainder), que representa las fluctuaciones no explicadas por los componentes de tendencia o estacionalidad, muestra una alta volatilidad, lo que sugiere la presencia de factores aleatorios e impredecibles que afectan el precio de Bitcoin, algo típico de los activos financieros volátiles. "],["preprocesamiento-y-visualización.html", "Capítulo 3 Preprocesamiento y Visualización 3.1 Descomposición 3.2 Estacionariedad 3.3 Diferenciación", " Capítulo 3 Preprocesamiento y Visualización El preprocesamiento y la visualización de una serie de tiempo son pasos fundamentales en una serie tan volátil como la del precio de Bitcoin, donde variaciones abruptas pueden distorsionar el análisis. Por otro lado, facilita la comprensión inicial de los patrones de tendencia, estacionalidad y ciclos en los datos, permitiendo detectar anomalías y proporcionar un contexto visual que guía decisiones analíticas. Así, estos procesos mejoran la capacidad de interpretar y predecir el comportamiento del Bitcoin en el tiempo. Descomposición Clásica: Es un método tradicional para descomponer una serie en sus componentes principales: tendencia, estacionalidad y ruido o residual. Esta técnica se basa en la premisa de que una serie temporal se puede desglosar en patrones observables que, cuando se suman o multiplican, generan el comportamiento de la serie completa. De aquí surgen dos modelos de descomposición: -Modelo Aditivo: Cuando los componentes se combinan de forma aditiva, siendo adecuado cuando la variación estacional es constante a lo largo del tiempo y no depende del nivel de la serie. -Modelo Multiplicativo: Cuando los componentes se combinan de forma multiplicativa, siendo adecuado cuando la estacionalidad y la tendencia varían en función del nivel de la serie, es decir, cuando los efectos estacionales son más fuertes en niveles altos de la serie. 3.1 Descomposición # Descomposición aditiva decomp_add &lt;- decompose(btc_ts, type = &quot;additive&quot;) # Convertir componentes en un data.frame y eliminar valores NA decomp_add_df &lt;- data.frame( time = as.numeric(time(btc_ts)), original = as.numeric(btc_ts), trend = as.numeric(decomp_add$trend), seasonal = as.numeric(decomp_add$seasonal), random = as.numeric(decomp_add$random) ) # Eliminar filas con NA decomp_add_df &lt;- na.omit(decomp_add_df) # Visualización de componentes aditivos ggplot(decomp_add_df, aes(x = time)) + geom_line(aes(y = original, color = &quot;Original&quot;)) + geom_line(aes(y = trend, color = &quot;Tendencia&quot;)) + geom_line(aes(y = seasonal, color = &quot;Estacionalidad&quot;)) + geom_line(aes(y = random, color = &quot;Residuo&quot;)) + labs(title = &quot;Descomposición Aditiva de la Serie de Bitcoin&quot;, y = &quot;Valor&quot;, color = &quot;Componentes&quot;) + scale_color_manual(values = c(&quot;Original&quot; = &quot;black&quot;, &quot;Tendencia&quot; = &quot;blue&quot;, &quot;Estacionalidad&quot; = &quot;red&quot;, &quot;Residuo&quot; = &quot;green&quot;)) + theme_minimal() La descomposición aditiva supone que la serie de tiempo es una suma de sus componentes: tendencia + estacionalidad + residuo. A través de este método, se observa que: Tendencia: Muestra una tendencia descendente desde mediados de 2021 hasta mediados de 2022, seguida de una recuperación gradual que continúa hasta 2024. Esta tendencia podría reflejar ciclos económicos o factores de mercado más amplios que afectan a Bitcoin. La tendencia sugiere que después de un periodo de declive, el mercado de Bitcoin comenzó a recuperar su valor en el último año, lo que podría indicar un periodo de recuperación o consolidación en el mercado. Estacionalidad: Muestra patrones que se repiten en ciclos regulares. La estacionalidad en este contexto podría estar relacionada con ciertos eventos recurrentes en el mercado de criptomonedas, como aumentos en la actividad comercial durante momentos específicos. La estacionalidad observada muestra oscilaciones regulares alrededor de cero, lo cual sugiere que hay ciertos patrones cíclicos que afectan el precio, aunque estos efectos son relativamente pequeños comparados con la tendencia y la volatilidad general de Bitcoin. Residuo: Muestra que, aunque podemos identificar patrones estacionales y una tendencia general, aún hay fluctuaciones impredecibles en el precio de Bitcoin que no son fáciles de modelar. # Descomposición multiplicativa decomp_mult &lt;- decompose(btc_ts, type = &quot;multiplicative&quot;) # Convertir componentes en un data.frame y eliminar valores NA decomp_mult_df &lt;- data.frame( time = as.numeric(time(btc_ts)), original = as.numeric(btc_ts), trend = as.numeric(decomp_mult$trend), seasonal = as.numeric(decomp_mult$seasonal), random = as.numeric(decomp_mult$random) ) # Eliminar filas con NA decomp_mult_df &lt;- na.omit(decomp_mult_df) # Convertir los datos a formato largo para usar facet_wrap decomp_mult_long &lt;- pivot_longer(decomp_mult_df, cols = c(&quot;original&quot;, &quot;trend&quot;, &quot;seasonal&quot;, &quot;random&quot;), names_to = &quot;component&quot;, values_to = &quot;value&quot;) # Graficar todos los componentes en un solo gráfico con facetas y escala logarítmica ggplot(decomp_mult_long, aes(x = time, y = value, color = component)) + geom_line(show.legend = FALSE) + scale_y_log10() + facet_wrap(~ component, scales = &quot;free_y&quot;, ncol = 1) + labs(title = &quot;Descomposición Multiplicativa de la Serie de Bitcoin&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor (Escala Logarítmica)&quot;) + theme_minimal() La descomposición multiplicativa supone que la serie de tiempo es el producto de sus componentes: tendencia x estacionalidad x residuo. A través de este método, se observa que: Tendencia: Muestra que esta es suave, es decir, no muestra un aumento progresivo en la variabilidad, lo que ayuda a identificar la dirección general sin verse afectada por fluctuaciones de corto plazo. Estacionalidad: Muestra patrones cíclicos que se repiten en el tiempo, lo que indica que existen ciertas fluctuaciones en el precio de Bitcoin que son predecibles y que siguen un ciclo regular. El hecho de que este componente sea proporcional a la tendencia sugiere que los cambios estacionales son más fuertes cuando el precio es alto y más débiles cuando el precio es bajo. Residuo: Muestra variaciones relativamente pequeñas alrededor de 1, lo cual sugiere que, en su mayoría, las oscilaciones de la serie pueden ser explicadas por la tendencia y la estacionalidad. Una vez análizados los dos métodos de descomposición, dado el comportamiento cíclico y proporcional a la tendencia del precio de Bitcoin, la descomposición multiplicativa es la más adecuada. 3.2 Estacionariedad El test de Dickey-Fuller, también conocido como prueba de raíz unitaria, determina si una serie temporal es estacionaria. La hipótesis nula del test asume que la serie tiene una raíz unitaria, es decir, que no es estacionaria. Si el valor p resultante es menor que el nivel de significancia 0.05, se rechaza la hipótesis nula, lo cual sugiere que la serie es estacionaria. # Realiza el test de Dickey-Fuller sobre la serie de tiempo resultado &lt;- adf.test(btc_ts) # Muestra el resultado print(resultado) ## ## Augmented Dickey-Fuller Test ## ## data: btc_ts ## Dickey-Fuller = -0.56974, Lag order = 11, p-value = 0.9787 ## alternative hypothesis: stationary En este caso se observa que el test Dickey-Fuller indica que la serie no es estacionaria, puesto que el valor p resultó mayor al nivel de significancia (0.05). En vista de lo anterior, se debe apliar diferenciación a la serie, para alcanzar la estacionariedad Se verifica el número de veces que se debe aplicar diferenciación para obtener estacionariedad. num_diffs &lt;- ndiffs(btc_ts) cat(&quot;El número de veces a diferenciar es&quot;, num_diffs, &quot;\\n&quot;) ## El número de veces a diferenciar es 1 3.3 Diferenciación Consiste en la transformación de la serie, restando su valor actual con el valor anterior, con el objetivo de eliminar tendencias o patrones de crecimiento a lo largo del tiempo, de manera que se convierta en una serie estacionaria. # Diferenciación de primer orden diff_btc &lt;- diff(btc_ts, lag=1) # Graficar con título y color plot(diff_btc, main = &quot;Diferenciación de primer orden del Precio de Bitcoin&quot;, ylab = &quot;diff_btc&quot;, xlab = &quot;Time&quot;, col = &quot;blue&quot;) Del gráfico se puede observar que, la serie diferenciada muestra una gran volatilidad al inicio, con diferencias que oscilan significativamente en ambos sentidos, indicando que los precios de Bitcoin estaban experimentando cambios bruscos, tanto al alza como a la baja. Posteriormente, la volatilidad disminuye, por lo que el precio atravesó por un periodo de estabilización, sin embargo, al final de la serie, se vuelve a presentar un incremento en la volatilidad. Por otra parte, la serie diferenciada parece oscilar alrededor de cero, esto es consecuencia de la eliminación de la tendencia. Finalmente, se realiza de nuevo el test de Dickey-Fuller. # Realiza el test de Dickey-Fuller sobre la serie de tiempo diferenciada resultado_diff &lt;- adf.test(diff_btc) ## Warning in adf.test(diff_btc): p-value smaller than printed p-value # Muestra el resultado diferenciado print(resultado_diff) ## ## Augmented Dickey-Fuller Test ## ## data: diff_btc ## Dickey-Fuller = -10.883, Lag order = 11, p-value = 0.01 ## alternative hypothesis: stationary En este caso, dado que el valor p es muy bajo (0.01), hay suficiente evidencia estadística para rechazar la hipótesis nula y aceptar la alternativa, es decir, que la serie diferenciada es estacionaria, por lo que la tendencia ha sido eliminada. Funciones ACF y PACF Las funciones de autocorrelación (ACF) y autocorrelación parcial (PACF) son herramientas para el análisis de series temporales, que permiten identificar patrones y a determinar los parámetros de los modelos ARIMA. En este caso, Para ajustar el modelo ARIMA, resulta fundamental determinar si se necesitan términos AR o MA para corregir cualquier autocorrelación que persista en la serie diferenciada. acf_diff &lt;- acf(diff_btc, main = &quot;Función de Autocorrelación de la Serie Diferenciada (ACF)&quot;) La ACF muestra un pico significativo en el rezago 1, lo cual indica que hay autocorrelación en el primer rezago de la serie diferenciada. En los rezagos posteriores, los valores de la ACF están dentro del rango de no significancia (dentro de las líneas azules), lo que indica que la serie no tiene autocorrelación fuerte a partir del segundo rezago. pacf_diff &lt;- pacf(diff_btc, main = &quot;Función de Autocorrelación Parcial de la Serie Diferenciada (PACF)&quot;) La PACF muestra varios picos en diferentes rezagos, aunque la mayoría están dentro del límite de no significancia. Este patrón sugiere una serie que tiene un componente autoregresivo, es decir, de tipo AR. Verificar Transformación de Box-Cox: Si bien al realizar la descomposición multiplicativa, el componente de tendencia parece seguir un ciclo suave, sin cambios bruscos en la amplitud, lo que sería un indicio de que la tendencia no muestra un aumento en la variabilidad, resulta necesario corroborar la necesidad o no de realizar transformaciones a la serie. Box-Cox se utiliza para encontar el mejor exponente para estabilizar la varianza. El valor de lambda será el que determine si resulta necesaria aplicar la transformación. # Calcular el valor de lambda óptimo para la transformación de Box-Cox lambda &lt;- BoxCox.lambda(btc_ts) print(lambda) ## [1] 0.4679757 # Aplicar la transformación de Box-Cox usando el valor de lambda btc_ts_transformed &lt;- BoxCox(btc_ts, lambda) # Escalar ambas series para llevarlas a la misma escala btc_ts_scaled &lt;- scale(btc_ts) btc_ts_transformed_scaled &lt;- scale(btc_ts_transformed) # Graficar ambas series en el mismo gráfico plot(btc_ts_scaled, type = &quot;l&quot;, col = &quot;blue&quot;, lty = 1, lwd = 2, main = &quot;Serie Original y Serie Transformada con Box-Cox (Escaladas)&quot;, ylab = &quot;Valor Escalado&quot;, xlab = &quot;Tiempo&quot;, ylim = c(-2, 4)) lines(btc_ts_transformed_scaled, col = &quot;red&quot;, lty = 2, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Serie Original (Escalada)&quot;, paste(&quot;Serie Transformada con Box-Cox (Escalada, λ =&quot;, round(lambda, 2), &quot;)&quot;)), col = c(&quot;blue&quot;, &quot;red&quot;), lty = c(1, 2), lwd = 2) Un valor de lambda entre 0 y 1 indica que la varianza de la serie aumenta con el nivel de los datos, pero no de manera tan pronunciada como para necesitar una transformación logarítmica completa, que es cuando lambda = 0. El valor de lambda obtenido sugiere que la relación entre el nivel de los datos y su varianza es moderada Por su parte, el gráfico muestra que la serie original escalada como la transformada están muy alineadas, en otras palabras, la transformación no altera significativamente la estructura de la serie. Esto sugiere que la serie original ya tiene una varianza estable y la transformación de Box-Cox no agrega un beneficio evidente en este caso. En conclusión, inicialmente no es estrictamente necesario aplicar una transformación a la serie para controlar la tendencia, dado que la diferenciación elimina este efecto. Tampoco es necesario aplicar una transformación para controlar la variabilidad, dado que la serie original muestra una varianza estable. "],["modelos-de-pronósticos-suavización-exponencial.html", "Capítulo 4 Modelos de Pronósticos (Suavización Exponencial) 4.1 Suavización Exponencial Simple 4.2 Modelo de Holt 4.3 Modelo de Holt-Winters 4.4 Resumen de Métricas", " Capítulo 4 Modelos de Pronósticos (Suavización Exponencial) Los modelos de pronóstico para series de tiempo son herramientas estadísticas que permiten anticipar valores futuros de una serie de datos a partir de sus registros históricos. Estas técnicas son esenciales en contextos donde los datos muestran fluctuaciones temporales y patrones que favorecen las proyecciones, como ocurre en activos financieros volátiles como Bitcoin. En este apartado se trabajará con la serie original, dado que, cuando se realizó la diferenciación a la serie, se eliminó la tendencia y disminuyó la estacionalidad, componentes que son necesarios para poder trabajar con modelos de suavización exponencial, que son no estacionarios, mientras que la serie diferenciada es más apta para modelos estacionarios. Cabe resaltar que, el pronóstico con suavización exponencial, asigna un mayor peso a los datos más recientes, atenuando la influencia de los datos más antiguos, lo que permite captar los patrones actuales sin depender en exceso de las observaciones históricas más lejanas. Los pronósticos se realizarán por los siguientes 10 días y manejando un intervalo de confianza del 95%. 4.1 Suavización Exponencial Simple Este modelo solo considera el nivel de la serie, es decir, el valor promedio reciente, ajustado con mayor peso a los valores más recientes. No tiene en cuenta la tendencia ni la estacionalidad, por lo que asume que la serie fluctúa alrededor de un valor constante. # Configurar la semilla para reproducibilidad set.seed(123) # Ajusta el modelo de suavización exponencial simple ses_btc &lt;- ses(btc_ts, h = 10, level = 95) # Graficar el pronóstico plot(ses_btc, main = &quot;Pronóstico de Suavización Exponencial Simple&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Valor&quot;, col = &quot;yellow&quot;, lwd = 1) # Añadir leyenda legend(&quot;top&quot;, legend = c(&quot;Datos Observados&quot;, &quot;Pronóstico Días SES&quot;, &quot;Intervalo de Confianza 95%&quot;), col = c(&quot;yellow&quot;, &quot;blue&quot;, &quot;grey&quot;), lty = c(1, 1, 2), lwd = c(1, 2, 1), cex = 0.7, horiz = FALSE) # Mostrar los valores de pronóstico de SES y los intervalos de confianza print(ses_btc) ## Point Forecast Lo 95 Hi 95 ## 2024.9205 97250.1 94429.26 100070.9 ## 2024.9233 97250.1 93334.56 101165.6 ## 2024.9260 97250.1 92485.04 102015.2 ## 2024.9288 97250.1 91765.57 102734.6 ## 2024.9315 97250.1 91130.10 103370.1 ## 2024.9342 97250.1 90554.68 103945.5 ## 2024.9370 97250.1 90024.93 104475.3 ## 2024.9397 97250.1 89531.46 104968.7 ## 2024.9425 97250.1 89067.70 105432.5 ## 2024.9452 97250.1 88628.85 105871.4 Se observa que la predicción es una línea horizontal, dado que asume que no hay crecimiento ni cambio estacional. En consecuencia, el modelo SES proyecta los valores futuros considerando únicamente el nivel de la serie, por lo cual puede resultar en predicciones similares para todos los períodos si no existen cambios significativos en los datos recientes. En este caso la proyección refleja valores aproximados homogéneos en USD 97,250.1 debido a la naturaleza del SES y la suavización empleada. 4.2 Modelo de Holt Conocido como suavización exponencial doble, se basa en un enfoque para el pronóstico de series de tiempo que maneja componentes de nivel y tendencia. Su atractivo radica en su capacidad de capturar la tendencia, a través de un segundo componente en la serie. Esto permite al modelo ajustarse a series que muestran una dirección (crecimiento o decrecimiento) a lo largo del tiempo. # Configurar la semilla para reproducibilidad set.seed(123) # Aplicar modelo de Holt con IC del 95% holt_model &lt;- holt(btc_ts, level = c(95)) # Realizar el pronóstico para los próximos 10 periodos forecasted_values &lt;- forecast(holt_model, h = 10) # Graficar la serie observada y el pronóstico plot(forecasted_values, main = &quot;Pronóstico de Holt&quot;, xlab = &quot;Time&quot;, ylab = &quot;Valor&quot;, col = &quot;green&quot;, lwd = 1) # Añadir leyenda legend(&quot;top&quot;, legend = c(&quot;Datos Observados&quot;, &quot;Pronóstico Días Holt&quot;, &quot;Intervalo de Confianza 95%&quot;), col = c(&quot;green&quot;, &quot;blue&quot;, &quot;grey&quot;), lty = c(1, 1, 2), lwd = c(1, 2, 1), cex = 0.7, horiz = FALSE) # Mostrar los valores de pronóstico de Holt y los intervalos de confianza print(forecasted_values) ## Point Forecast Lo 95 Hi 95 ## 2024.9205 97767.47 94923.23 100611.7 ## 2024.9233 98268.29 94299.34 102237.2 ## 2024.9260 98769.11 93891.76 103646.5 ## 2024.9288 99269.93 93594.85 104945.0 ## 2024.9315 99770.75 93366.42 106175.1 ## 2024.9342 100271.57 93184.68 107358.5 ## 2024.9370 100772.39 93036.68 108508.1 ## 2024.9397 101273.21 92914.03 109632.4 ## 2024.9425 101774.03 92810.95 110737.1 ## 2024.9452 102274.85 92723.25 111826.4 Observando los valores pronosticados, parece haber una ligera tendencia ascendente en los próximos periodos, donde el valor pronosticado va aumentando del primer día al décimo día. Para el primer pronóstico se encuentra que, dadas las condiciones y el comportamiento histórico de la serie, con un nivel de confianza del 95%, el valor del activo es poco probable que caiga por debajo de aproximadamente USD 94,923.23 o supere USD 100,611.7. Por otra parte, la gran amplitud del intervalo de confianza indica que el pronóstico es altamente incierto. Esto refleja la naturaleza volátil de la serie diferenciada de Bitcoin, donde los datos fluctúan continuamente y el modelo tiene dificultades para capturar patrones predecibles. Esto también se debe a que el modelo de Holt no asume una relación directa entre el nivel de la serie y la variabilidad futura. Como complemento es necesario destacar que, en este tipo de modelos, la incertidumbre se acumula en el tiempo de manera que los intervalos de confianza tienden a expandirse conforme se proyecta hacia adelante. Esto significa que el rango de los intervalos aumenta con el horizonte de predicción, pero no en proporción directa al nivel estimado. 4.3 Modelo de Holt-Winters Conocido como suavización exponencial triple, contempla componentes de nivel, tendencia y estacionalidad. Su atractivo radica en su capacidad de capturar la estacionalidad, a través de un tercer componente en la serie. Ahora, se proede con la generación del modelo de Holt-Winters completo, en este caso el aditivio, que es adecuado para series con estacionalidad de magnitud constante. # Configurar la semilla para reproducibilidad set.seed(123) # Aplicar el modelo Holt-Winters aditivo hw_additive_model &lt;- HoltWinters(btc_ts, seasonal = &quot;additive&quot;) ## Warning in HoltWinters(btc_ts, seasonal = &quot;additive&quot;): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH # Realizar el pronóstico para los próximos 10 periodos forecasted_values_additive &lt;- forecast(hw_additive_model, h = 10, level = 95) # Graficar la serie observada y el pronóstico con intervalos de confianza plot(forecasted_values_additive, main = &quot;Pronóstico de Holt-Winters Aditivo&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Valor&quot;, col = &quot;red&quot;, lwd = 1) # Añadir leyenda legend(&quot;top&quot;, legend = c(&quot;Datos Observados&quot;, &quot;Pronóstico Días Holt-Winters&quot;, &quot;Intervalo de Confianza 95%&quot;), col = c(&quot;red&quot;, &quot;blue&quot;, &quot;grey&quot;), lty = c(1, 1, 2), lwd = c(1, 2, 1), cex = 0.7, horiz = FALSE) # Mostrar los valores de pronóstico de Holt y los intervalos de confianza print(forecasted_values_additive) ## Point Forecast Lo 95 Hi 95 ## 2024.9205 95000.67 91653.51 98347.83 ## 2024.9233 91698.81 87358.24 96039.37 ## 2024.9260 90697.60 85547.69 95847.50 ## 2024.9288 90947.06 85095.01 96799.11 ## 2024.9315 91219.24 84737.29 97701.20 ## 2024.9342 91576.05 84517.07 98635.04 ## 2024.9370 89506.88 81911.67 97102.10 ## 2024.9397 88693.09 80594.33 96791.84 ## 2024.9425 89511.00 80935.62 98086.37 ## 2024.9452 90991.66 81962.32 100021.01 El pronóstico muestra una tendencia ligeramente descendente, en concordancia con el comportamiento reciente de la serie. Esto podría indicar que el modelo de Holt-Winters está captando una posible estabilización o ligera reducción en los precios en los próximos periodos, reflejando el comportamiento de corto plazo observado al final de la serie histórica. Para el primer periodo proyectado, el intervalo de confianza del 95% se encuentra aproximadamente entre USD 91,653.51 y USD 98,347.83. Esto significa que, con un 95% de confianza, se espera que el valor real del activo caiga dentro de este rango, proporcionando un margen de variabilidad para el valor futuro. Además, los amplios intervalos de confianza reflejan la naturaleza volátil de la serie de tiempo. Estos intervalos muestran una considerable incertidumbre en las proyecciones futuras, lo que es típico en series con alta variabilidad como esta. La amplitud de los intervalos se incrementa a medida que avanza el horizonte de pronóstico, lo que indica que la confianza en las proyecciones disminuye en periodos más lejanos debido a la acumulación de error en el tiempo. 4.4 Resumen de Métricas La elección del tipo de suavización exponencial depende de la estructura de la serie de tiempo, y de los resultados obtenidos al evaluar las métricas de precisión para determinar su efectividad. # Ajustar los modelos ses_model &lt;- ses(btc_ts, h = 5, level = 95) holt_model &lt;- holt(btc_ts, level = c(95)) hw_additive_model &lt;- HoltWinters(btc_ts, seasonal = &quot;additive&quot;) ## Warning in HoltWinters(btc_ts, seasonal = &quot;additive&quot;): optimization difficulties: ERROR: ## ABNORMAL_TERMINATION_IN_LNSRCH # Calcular las métricas de precisión para cada modelo metrics_ses &lt;- forecast::accuracy(ses_model$fitted, diff_btc) metrics_holt &lt;- forecast::accuracy(holt_model$fitted, diff_btc) metrics_hw_additive &lt;- forecast::accuracy(hw_additive_model$fitted[,1], diff_btc) # Extraer y mostrar las métricas importantes para cada modelo ses_metrics &lt;- data.frame( Model = &quot;SES&quot;, MAE = metrics_ses[&quot;Test set&quot;, &quot;MAE&quot;], RMSE = metrics_ses[&quot;Test set&quot;, &quot;RMSE&quot;], MAPE = metrics_ses[&quot;Test set&quot;, &quot;MAPE&quot;], ACF1 = metrics_ses[&quot;Test set&quot;, &quot;ACF1&quot;], TheilsU = metrics_ses[&quot;Test set&quot;, &quot;Theil&#39;s U&quot;] ) holt_metrics &lt;- data.frame( Model = &quot;Holt&quot;, MAE = metrics_holt[&quot;Test set&quot;, &quot;MAE&quot;], RMSE = metrics_holt[&quot;Test set&quot;, &quot;RMSE&quot;], MAPE = metrics_holt[&quot;Test set&quot;, &quot;MAPE&quot;], ACF1 = metrics_holt[&quot;Test set&quot;, &quot;ACF1&quot;], TheilsU = metrics_holt[&quot;Test set&quot;, &quot;Theil&#39;s U&quot;] ) hw_additive_metrics &lt;- data.frame( Model = &quot;Holt-Winters Additive&quot;, MAE = metrics_hw_additive[&quot;Test set&quot;, &quot;MAE&quot;], RMSE = metrics_hw_additive[&quot;Test set&quot;, &quot;RMSE&quot;], MAPE = metrics_hw_additive[&quot;Test set&quot;, &quot;MAPE&quot;], ACF1 = metrics_hw_additive[&quot;Test set&quot;, &quot;ACF1&quot;], TheilsU = metrics_hw_additive[&quot;Test set&quot;, &quot;Theil&#39;s U&quot;] ) # Combina los resultados en una tabla all_metrics &lt;- rbind(ses_metrics, holt_metrics, hw_additive_metrics) print(all_metrics) ## Model MAE RMSE MAPE ACF1 TheilsU ## 1 SES 41375.87 44796.25 51334.59 0.9786711 96.60984 ## 2 Holt 41444.47 44894.46 51379.13 0.9787384 96.61733 ## 3 Holt-Winters Additive 39312.67 43491.04 60665.30 0.9837329 95.07895 El modelo Holt-Winters Aditivo tiene el menor error medio absoluto (MAE), lo que indica que, en promedio, es el que menos se desvía de los valores reales. De igual forma, presenta el menor error cuadrático medio (RMSE), lo que refuerza que este modelo tiene una mayor precisión al reducir el impacto de grandes errores en comparación con los otros modelos. Sin embargo, muestra un error porcentual absoluto medio (MAPE) más alto, lo que sugiere que, aunque es más preciso en términos absolutos, su desempeño es menos consistente cuando se observa en términos relativos (porcentuales), lo cual indica cierta variabilidad en su precisión. Además, todos los modelos presentan una alta autocorrelación en los errores (ACF1). Esto puede señalar que aún existe un patrón en los errores de predicción que no ha sido completamente captado por los modelos, lo cual podría afectar la calidad de las predicciones a lo largo del tiempo. Finalmente, todos los modelos muestran un valor alto en el índice de Theil’s U. En general, un valor de Theil’s U cercano a 0 indica un buen desempeño en comparación con un modelo de referencia (ingenuo), mientras que un valor cercano a uno, sugiere que el modelo de pronóstico podría no ser adecuado. Lo expuesto hasta aquí, indica que, el uso de modelos no estacionarios, como Holt, Holt-Winters y Suavización Exponencial Simple, en series altamente volátiles como la de Bitcoin presenta varios desafíos que limitan la precisión y consistencia de los pronósticos. Su dependencia de tendencias y suavización para hacer pronósticos a corto y mediano plazo es menos efectiva cuando el activo subyacente muestra comportamientos erráticos y cambios bruscos en el valor. Esto justifica por qué, aunque el modelo Holt-Winters Aditivo es el mejor en términos absolutos, su desempeño no es consistente ni óptimo en términos relativos para una serie tan impredecible. "],["modelos-estacionarios.html", "Capítulo 5 Modelos Estacionarios 5.1 Modelo ARIMA (Auto) 5.2 Modelo ARIMA (Manual) 5.3 Comparación de modelos", " Capítulo 5 Modelos Estacionarios Los modelos estacionarios desempeñan un papel crucial en el análisis de series temporales. Una serie temporal se clasifica como estacionaria cuando sus propiedades estadísticas, como la media, la varianza y la autocorrelación, permanecen constantes a lo largo del tiempo. En los modelos estacionarios, las relaciones entre puntos en el tiempo son consistentes, lo que permite predecir con mayor precisión futuros valores basados en el pasado. Esto es crucial en aplicaciones como finanzas. 5.1 Modelo ARIMA (Auto) La metodología Box-Jenkins se utiliza para construir modelos ARIMA (p,d,q), que contiene componentes AR (Autoregresivo), I (Integrado) y MA (Media Móvil): Visualización de la serie: Ayuda a decidir si es necesario transformar la serie para estabilizar su varianza o hacerla estacionaria. # Graficar la serie plot(btc_ts, main = &quot;Serie Precio Bitcoin&quot;, ylab = &quot;USD&quot;, xlab = &quot;Tiempo&quot;, col = &quot;blue&quot;, type = &quot;l&quot;) abline(reg = lm(btc_ts ~ time(btc_ts)), col = &quot;red&quot;, lty = 2) Se observa que la amplitud de las oscilaciones aumenta con el nivel de la serie, lo que supone que la varianza no es constante. Adicional, se observa una tendencia ascendente en el precio y posibles ciclos repetitivos, razón por la cual se sugiere realizar una transformación logarítmica. plot(log(btc_ts),main=&quot;Precio Bitcoin&quot;,xlab=&quot;Tiempo&quot;,ylab=&quot;log (USD)&quot;, col = &quot;brown&quot;, type = &quot;l&quot;) grid() Transformación en Estacionaria: La estacionariedad se refiere a una característica de un proceso estocástico en la que las propiedades estadísticas del proceso no cambian con el tiempo. # Guardar nuevo vector con log btc_ts_log &lt;- log(btc_ts) # Diferenciar la serie diff_btc2 &lt;- diff(btc_ts_log) # Graficar la serie diferenciada del logaritmo plot(diff_btc2, main = &quot;Serie Diferenciada del Precio Bitcoin&quot;, ylab = &quot;Diferencias&quot;, xlab = &quot;Tiempo&quot;, col = &quot;blue&quot;, type = &quot;l&quot;) # Verificar estacionariedad tras la diferenciación adf.test(diff_btc2) ## Warning in adf.test(diff_btc2): p-value smaller than printed p-value ## ## Augmented Dickey-Fuller Test ## ## data: diff_btc2 ## Dickey-Fuller = -10.886, Lag order = 11, p-value = 0.01 ## alternative hypothesis: stationary Se observa que el valor p de la prueba ADF es menor a 0.05 tras la diferenciación, entonces la serie diferenciada es estacionaria y está lista para modelar. Identificación de Parámetros: Las funciones ACF y PACF ayudan a identificar los parámetros p (Autoregresivo) y q (Media Móvil). # Graficar la ACF y PACF par(mfrow = c(1, 2)) # Dividir la ventana gráfica acf(diff_btc2, main = &quot;ACF&quot;) # Identificar q pacf(diff_btc2, main = &quot;PACF&quot;) # Identificar p par(mfrow = c(1, 1)) # Restaurar la ventana gráfica Los cortes en la ACF indican el orden q y los cortes en la PACF indican el orden p. Así, el gráfico ACF establece que, hay un corte significativo en el lag 1 y los demás valores están dentro de las bandas de confianza (parecen insignificantes). Esto indica un componente MA (q=1). Por su parte, también se observa un corte significativo en el lag 1, lo que indica la presencia de un componente AR (p=1). Ahora, como previamente se realizó una diferenciación, entonces se tiene que (d=0). Así, visualmente el modelo ARIMA sería (1,0,1) Construcción del modelo: A través de la función autoarima, se obtendrá el modelo de ajuste y se comparará con el modelo visual. modelo_arima_diff &lt;- auto.arima(diff_btc2) summary(modelo_arima_diff) ## Series: diff_btc2 ## ARIMA(1,0,0) with zero mean ## ## Coefficients: ## ar1 ## -0.0307 ## s.e. 0.0265 ## ## sigma^2 = 0.001059: log likelihood = 2869.44 ## AIC=-5734.88 AICc=-5734.87 BIC=-5724.35 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 0.0008628861 0.03253173 0.02234498 97.01396 111.0288 0.6934362 0.0004402093 La función sugiere un modelo ARIMA(1,0,0): El modelo ajustado incluye un único término autoregresivo (p=1), no incluye componente de integración, dado que la serie fue diferenciada previamente (d=0), y no presenta un componente de media móvil (q=0). En otras palabras, la función indica que dada la naturaleza de los datos, el mejor modelo sería un modelo AR1 (AutoRegresivo). Un modelo AR(1) implica que el valor de la serie en el tiempo t depende principalmente de su valor en el tiempo t−1. El hecho de que no se incluya el término de media móvil (MA) sugiere que no hay una dependencia significativa entre los errores pasados, lo cual es común en series donde los choques o errores aleatorios no afectan significativamente a los valores futuros. El valor del coeficiente AR 1 es negativo, lo que indica una relación inversa entre el valor actual y el valor del período anterior, sin embargo, el coeficiente es muy pequeño, lo que sugiere que el efecto autoregresivo es débil. La significancia del coeficiente se evalúa con el valor t, aproximadamente: -0.0307/0.0265 = -1.15, como este valor t es &lt; 2, entonces el coeficiente no es estadísticamente significativo al nivel de confianza estándar 0.05 La varianza de los residuos muestra un valor bajo. AIC es negativo, lo cual es una buena señal de ajuste (valores más bajos son mejores). BIC es negativo, similar al AIC, se usa para comparar modelos. Valores más bajos indican un mejor ajuste penalizando la complejidad. Por otra parte, las métricas se utilizan para evaluar el rendimiento del modelo en términos de la precisión del ajuste. Menores valores indican un mejor desempeño: El error medio es cercano a cero, significa que el modelo no tiene un sesgo sistemático en las predicciones, es decir, no subestima ni sobreestima de manera constante. El modelo tiene errores absolutos bajos (MAE), lo cual indica un buen ajuste. Los valores de MPE y MAPE son altos, lo que indica que el modelo no es completamente preciso en términos porcentuales. Esto podría deberse a una alta variabilidad en los datos originales o a la presencia de valores extremos. El MASE indica que el modelo es mejor que un modelo de referencia, lo cual es un buen indicador. La baja autocorrelación en los residuos (ACF1) respalda que el modelo ARIMA está capturando adecuadamente las dependencias temporales. Diagnóstico del modelo ARIMA(1,0,0): Consiste en evaluar si el modelo captura adecuadamente las dinámicas de la serie temporal mediante el análisis de los residuos. Los residuos deben comportarse como un proceso de ruido blanco, es decir, ser independientes, no correlacionados, con media cero y varianza constante. Además, se debe verificar si están distribuidos aproximadamente de manera normal, lo que respalda la validez de las inferencias estadísticas del modelo. # Diagnóstico del modelo tsdiag(modelo_arima_diff) # Prueba de Ljung-Box Box.test(residuals(modelo_arima_diff), lag = 11, type = &quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: residuals(modelo_arima_diff) ## X-squared = 14.552, df = 11, p-value = 0.2039 Los residuos parecen oscilar alrededor de 0. No se observan patrones evidentes, lo cual es una buena señal, dado que sugiere que el modelo está capturando correctamente la estructura de la serie. Adicional, la mayoría de los puntos están dentro de las bandas de confianza (líneas azules), lo que indica que no hay autocorrelaciones significativas en los residuos. La gráfica de valores p, muestra que para la mayoría de los lags, los valores p están por encima del nivel de significancia de 0.05 (línea azul). Esto indica que no se puede rechazar la hipótesis nula de que los residuos son ruido blanco, lo cual se corrobora con el test Box-Ljung. En consencuencia, los residuos son independientes y no presentan correlación significativa, lo que valida el buen ajuste del modelo. Predicciones: Consisten en utilizar el modelo ajustado para proyectar valores futuros de la serie temporal, basándose en las relaciones identificadas durante el ajuste. Las predicciones pueden incluir intervalos de confianza, que proporcionan una estimación del rango en el que es probable que se encuentren los valores futuros con un nivel de certeza especificado (por ejemplo, 95%). # Pronóstico para los próximos 10 días pronostico &lt;- forecast(modelo_arima_diff, h = 10, level = 95) # Gráfico del pronóstico plot(pronostico, main = &quot;Pronóstico Precios Bitcoin con auto.arima&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Log Precio USD&quot;) # Agregar una cuadrícula al gráfico grid() # Diagnóstico de residuos checkresiduals(modelo_arima_diff) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,0,0) with zero mean ## Q* = 287.44, df = 285, p-value = 0.4484 ## ## Model df: 1. Total lags used: 286 # Mostrar el pronóstico pronostico ## Point Forecast Lo 95 Hi 95 ## 2024.9205 -2.632493e-04 -0.06404658 0.06352008 ## 2024.9233 8.080422e-06 -0.06380529 0.06382145 ## 2024.9260 -2.480281e-07 -0.06381365 0.06381315 ## 2024.9288 7.613206e-09 -0.06381339 0.06381341 ## 2024.9315 -2.336869e-10 -0.06381340 0.06381340 ## 2024.9342 7.173004e-12 -0.06381340 0.06381340 ## 2024.9370 -2.201749e-13 -0.06381340 0.06381340 ## 2024.9397 6.758255e-15 -0.06381340 0.06381340 ## 2024.9425 -2.074442e-16 -0.06381340 0.06381340 ## 2024.9452 6.367487e-18 -0.06381340 0.06381340 Los valores pronosticados y los intervalos de confianza muestran una tendencia a estabilizarse rápidamente. Esto sugiere que el modelo ARIMA(1,0,0) ha capturado una dinámica estacionaria en la serie temporal. En otras palabras, sugiere que la serie temporal ha alcanzado un nivel constante después de ser diferenciada, y no se espera una tendencia ascendente o descendente significativa. Aunque los valores pronosticados son cercanos a 0, los intervalos de confianza indican una variabilidad moderada, pero no grandes oscilaciones futuras. Este pronóstico confirma que la diferenciación del modelo ha eliminado cualquier tendencia, dejando una serie estacionaria alrededor de 0. Por otra parte, la ausencia de patrones persistentes sugiere que los residuos son independientes en el tiempo. La forma de la distribución de los residuos es aproximadamente simétrica y se asemeja a una distribución normal. Normalidad en los residuos: El test de Shapiro-Wilk evalúa si los residuos de un modelo se distribuyen normalmente. Esto es importante porque uno de los supuestos básicos de los modelos ARIMA es que los errores (residuos) deben seguir una distribución normal con media cero y varianza constante. residuales&lt;-modelo_arima_diff$residuals qqnorm(residuales) qqline(residuales) shapiro.test(residuales) ## ## Shapiro-Wilk normality test ## ## data: residuales ## W = 0.94689, p-value &lt; 2.2e-16 Aunque el análisis gráfico mostró que la distribución de los residuos es aproximadamente simétrica y parece cercana a una normal, el test de Shapiro-Wilk detecta una desviación significativa de la normalidad, probablemente debido a la alta sensibilidad que presenta el test ante tamaños de muestra grandes. De todas formas, Si los residuos son ruido blanco y no tienen autocorrelación significativa (como lo confirmó el test de Ljung-Box), el modelo sigue siendo válido para predicción, incluso si los residuos no son perfectamente normales. 5.2 Modelo ARIMA (Manual) Cuando se revisarón los cortes en la ACF y en la PACF, se sugirió un modelo ARIMA (1,0,1), por lo que ahora se evaluará la implementación del mismo, para medir su rendimiento en comparación con el modelo ARIMA (1,0,0). Construcción del modelo: De forma visual se selecciona un modelo ARIMA(1,0,1). arima_model &lt;- Arima(diff_btc2, order = c(1, 0, 1)) summary(arima_model) ## Series: diff_btc2 ## ARIMA(1,0,1) with non-zero mean ## ## Coefficients: ## ar1 ma1 mean ## -0.5367 0.5019 8e-04 ## s.e. 0.3178 0.3243 8e-04 ## ## sigma^2 = 0.001059: log likelihood = 2870.47 ## AIC=-5732.93 AICc=-5732.9 BIC=-5711.87 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 2.450192e-06 0.03250836 0.02235837 97.98546 140.3593 0.6938518 0.004887155 El coeficiente AR(1) es negativo, lo que indica una relación inversa entre el valor actual y el valor del período anterior. Este valor sugiere que un aumento en t−1 tiende a estar asociado con una disminución en t. Como el coeficiente es moderadamente significativo, implica un efecto autoregresivo notable. El coeficiente MA(1) es positivo, indicando que el error del período anterior contribuye positivamente al valor actual. Este término refleja que el modelo está ajustando fluctuaciones no explicadas de manera razonable. La significancia de los coeficientes puede evaluarse con sus valores t, aproximadamente: Para AR(1): -0.5367/0.3178 = −1.68. Para MA(1): 0.5019/0.3423 = 1.46. Ambos valores t son menores a 2, lo que sugiere que los coeficientes no son estadísticamente significativos al nivel estándar p &gt; 0.05. La varianza de los residuos es baja, lo que indica que el modelo captura bien las fluctuaciones de los datos. Los valores de AIC y BIC son negativos, lo cual es una buena señal de ajuste. Estos valores bajos indican que el modelo tiene un buen equilibrio entre precisión del ajuste y complejidad del modelo. Por el lado de las métricas se tiene que: El error medio (ME) es muy cercano a cero, lo que implica que el modelo no presenta un sesgo sistemático en las predicciones, es decir, no subestima ni sobreestima de manera consistente. El modelo tiene un error absoluto bajo, lo que indica que las predicciones son precisas en términos absolutos. Los valores de Error porcentual medio y Error Porcentual Absoluto Medio - MPE y MAPE son altos, lo que sugiere que el modelo no es completamente preciso en términos porcentuales. Esto podría deberse a la naturaleza de los datos originales, que tal vez incluyen alta variabilidad o valores extremos. El Error Absoluto Escalado Medio - MASE indica que el modelo es mejor que un modelo de referencia basado en promedios simples, lo cual es un buen indicador del rendimiento. La autocorrelación en los errores es baja, lo que respalda que el modelo está capturando adecuadamente las dependencias temporales de la serie. Diagnóstico del modelo ARIMA(1,0,1): Es importante verificar si los residuos del modelo se comportan como ruido blanco (independientes y distribuidos normalmente). # Diagnóstico del modelo tsdiag(arima_model) # Prueba de Ljung-Box Box.test(residuals(arima_model), lag = 11, type = &quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: residuals(arima_model) ## X-squared = 13.355, df = 11, p-value = 0.2707 Los residuales parecen oscilar alrededor de cero, lo cual es consistente con el supuesto de que son ruido blanco (media cero). No se observan patrones evidentes, tendencias o estacionalidad en los residuales, lo que indica que el modelo ha capturado bien las dinámicas de la serie. La amplitud de los residuos parece constante en el tiempo, lo que respalda la suposición de homocedasticidad (varianza constante). Los gráficos indican que el modelo es adecuado para los datos. Los residuales son ruido blanco, con media cero, varianza constante, y sin autocorrelación significativa. Predicciones: Se realizan predicciones y se grafican los resultados. # Pronóstico para los próximos 10 días pronostico_manual &lt;- forecast(arima_model, h = 10, level = 95) # Gráfico del pronóstico plot(pronostico_manual, main = &quot;Pronóstico Precios Bitcoin con arima manual&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Log Precio USD&quot;) # Agregar una cuadrícula al gráfico grid() # Diagnóstico de residuos checkresiduals(arima_model) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,0,1) with non-zero mean ## Q* = 287.16, df = 284, p-value = 0.4365 ## ## Model df: 2. Total lags used: 286 # Mostrar el pronóstico pronostico_manual ## Point Forecast Lo 95 Hi 95 ## 2024.9205 0.0001160769 -0.06366609 0.06389824 ## 2024.9233 0.0012203533 -0.06260062 0.06504132 ## 2024.9260 0.0006276332 -0.06320451 0.06445978 ## 2024.9288 0.0009457756 -0.06288959 0.06478114 ## 2024.9315 0.0007750128 -0.06306128 0.06461131 ## 2024.9342 0.0008666697 -0.06296989 0.06470323 ## 2024.9370 0.0008174729 -0.06301917 0.06465411 ## 2024.9397 0.0008438792 -0.06299278 0.06468054 ## 2024.9425 0.0008297056 -0.06300696 0.06466637 ## 2024.9452 0.0008373133 -0.06299936 0.06467398 Los residuales se comportan como ruido blanco: no presentan autocorrelación significativa ni patrones evidentes, lo cual indica que el modelo está ajustado adecuadamente. La distribución de los residuos es razonablemente cercana a la normal, lo que respalda la validez de las inferencias y predicciones del modelo. Ahora, aunque los residuos son cercanos a la normalidad, se observa una ligera asimetría en las colas del histograma. Esto podría indicar la presencia de algunos valores extremos o una ligera desviación de la normalidad. Normalidad en los residuos: El test de Shapiro-Wilk es una prueba estadística utilizada para evaluar si los residuos de un modelo ARIMA (o cualquier otro modelo) siguen una distribución normal. Este test compara la distribución observada de los residuos con una distribución normal teórica. residuales_manual&lt;-arima_model$residuals qqnorm(residuales_manual) qqline(residuales_manual) shapiro.test(residuales_manual) ## ## Shapiro-Wilk normality test ## ## data: residuales_manual ## W = 0.947, p-value &lt; 2.2e-16 La falta de normalidad en los residuos no necesariamente invalida el modelo si los residuos siguen siendo ruido blanco (independientes y no correlacionados), lo cual se verifica a través de otros diagnósticos como la ACF y el test de Ljung-Box, sin embargo, una desviación significativa de la normalidad puede afectar la confiabilidad de los intervalos de predicción generados por el modelo. En este caso, al igual que el modelo con autoarima, se obtiene que visualmente se muestra una distribución normal de los residuos, pero con el test, se establece que se puede rechazar la hipótesis nula de que los residuos siguen una distribución normal. Lo anterior sugiere recurrir a modelos alternativos para abordar la falta de normalidad en los residuos. Entre estos se encuentran los modelos GARCH, EGARCH, GJR-GARCH, ARFIMA, entre otros. 5.3 Comparación de modelos Se implementarons los modelos ARIMA (1,0,0) y ARIMA (1,0,1), una vez revisadas sus métricas de desempeño, se concluye que, para la serie de tiempo del Precio de Bitcoin: Aunque el ARIMA(1,0,1) tiene un log-likelihood ligeramente mayor y menor RMSE, la diferencia es mínima. Además, el ARIMA(1,0,0) muestra un mejor desempeño en AIC, AICc y BIC, lo que sugiere un modelo más eficiente en términos de simplicidad. El ARIMA(1,0,0)) tiene un MAPE significativamente más bajo, lo que sugiere que genera predicciones más precisas en términos porcentuales. ARIMA(1,0,1) introduce un parámetro adicional (MA1) pero este no aporta mejoras significativas al modelo. La penalización de complejidad reflejada en el BIC favorece al ARIMA(1,0,0). El ARIMA(1,0,0) tiene menor autocorrelación en los residuos, indicando que captura mejor las dependencias temporales. La diferencia entre ambos modelos es marginal, pero ARIMA(1,0,0) es más eficiente porque logra un desempeño casi igual al ARIMA(1,0,1) con menos complejidad. En aplicaciones prácticas, la simplicidad y menor penalización por complejidad hacen al ARIMA(1,0,0) preferible. "],["modelos-de-regresión.html", "Capítulo 6 Modelos de Regresión 6.1 Modelo Prophet 6.2 Comparación con ARIMA y ETS 6.3 Selección del mejor modelo", " Capítulo 6 Modelos de Regresión La regresión en series de tiempo es una herramienta útil para modelar y analizar relaciones entre variables dependientes y predictoras cuando existe una estructura temporal subyacente. Sin embargo, la estacionariedad es una consideración clave para garantizar que los parámetros estimados sean consistentes y significativos. Si las series de tiempo involucradas no son estacionarias, los resultados del modelo pueden ser engañosos, llevando a conclusiones incorrectas sobre las relaciones entre las variables. 6.1 Modelo Prophet El modelo Prophet es un algoritmo de pronóstico de series de tiempo desarrollado por Facebook, diseñado para manejar datos con tendencias no lineales y patrones estacionales recurrentes, incluso en presencia de datos faltantes, valores atípicos y puntos de cambio en la tendencia. Utiliza un enfoque aditivo, descomponiendo la serie en componentes principales como tendencia, estacionalidad y efectos de eventos específicos. Prophet es ideal para series de tiempo con alta granularidad (diaria o semanal) y es capaz de incorporar variables externas y eventos futuros para mejorar la precisión del pronóstico. btc_final_df &lt;- data.frame( ds = as.Date(index(btc_final)), y = as.numeric(coredata(btc_final)) ) # Ajustar el modelo Prophet model_prophet &lt;- prophet(btc_final_df, daily.seasonality = TRUE ) # Crear un marco para predicciones futuras (10 días adicionales) future &lt;- make_future_dataframe(model_prophet, periods = 10) # Hacer las predicciones forecast &lt;- predict(model_prophet, future) # Visualizar el pronóstico plot(model_prophet, forecast, xlab = &quot;Tiempo&quot;, ylab = &quot;Precio USD&quot;) + ggtitle(&quot;Pronóstico con Prophet&quot;) # Asegurarse de que ambas columnas ds tengan la misma zona horaria btc_final_df$ds &lt;- as.POSIXct(btc_final_df$ds, tz = &quot;UTC&quot;) forecast$ds &lt;- as.POSIXct(forecast$ds, tz = &quot;UTC&quot;) #Obtener los valores de las predicciones forecast_10d &lt;- tail(forecast[forecast$ds &gt; max(btc_final_df$ds), ], 10) forecast_10d[, c(&quot;ds&quot;, &quot;yhat&quot;, &quot;yhat_lower&quot;, &quot;yhat_upper&quot;)] ## ds yhat yhat_lower yhat_upper ## 1432 2024-12-02 81175.18 75776.10 86887.44 ## 1433 2024-12-03 80861.15 75189.88 86353.02 ## 1434 2024-12-04 80790.72 75083.92 86726.76 ## 1435 2024-12-05 80465.09 74877.86 85747.82 ## 1436 2024-12-06 80241.28 74459.87 86114.35 ## 1437 2024-12-07 80013.18 74310.98 85453.19 ## 1438 2024-12-08 79869.33 74579.16 85983.35 ## 1439 2024-12-09 79727.41 74174.99 85149.03 ## 1440 2024-12-10 79458.61 73940.69 85023.46 ## 1441 2024-12-11 79463.77 73957.92 84815.32 # Crear un gráfico simple ggplot(forecast_10d, aes(x = ds, y = yhat)) + geom_line(color = &quot;blue&quot;) + geom_ribbon(aes(ymin = yhat_lower, ymax = yhat_upper), alpha = 0.2) + labs(title = &quot;Pronóstico para los Próximos 10 Días del Precio del Bitcoin&quot;, x = &quot;Fecha&quot;, y = &quot;Precio USD&quot;) + theme_minimal() El modelo Prophet genera intervalos de confianza para las predicciones basados en la incertidumbre de los componentes del modelo (tendencia, estacionalidad y error). Por defecto, Prophet maneja un intervalo de confianza del 80%. En este caso al realizar las predicciones se observa que, la amplitud de las bandas de confianza aumenta en el futuro, lo que refleja una mayor incertidumbre en las predicciones. El modelo predice una ligera disminución en el precio durante los próximos 10 días, mostrando una tendencia de estabilización o leve corrección. La zona sombreada indica que, aunque el precio central muestra un ligero descenso, existe una probabilidad considerable de que el precio se mantenga dentro del rango estimado (aproximadamente entre 73,000 y 84,000 USD). 6.2 Comparación con ARIMA y ETS # Dividir los datos en entrenamiento y prueba splits &lt;- initial_time_split(btc_final_df, prop = 0.9) # Modelo 1: ARIMA model_arima &lt;- arima_reg() %&gt;% set_engine(&quot;auto_arima&quot;) %&gt;% fit(y ~ ds, data = training(splits)) ## frequency = 7 observations per 1 week # Modelo 2: ETS (Suavizamiento Exponencial) model_ets &lt;- exp_smoothing() %&gt;% set_engine(&quot;ets&quot;) %&gt;% fit(y ~ ds, data = training(splits)) ## frequency = 7 observations per 1 week # Modelo 3: Prophet model_prophet &lt;- prophet_reg( seasonality_daily = FALSE, seasonality_weekly = TRUE, seasonality_yearly = TRUE ) %&gt;% set_engine(engine = &quot;prophet&quot;) %&gt;% fit(y ~ ds, data = training(splits)) # Crear tabla de modelos models_tbl &lt;- modeltime_table( model_arima, model_ets, model_prophet ) # Calibración de los modelos calibration_tbl &lt;- models_tbl %&gt;% modeltime_calibrate(new_data = testing(splits)) # Predicciones en el set de pruebas calibration_tbl %&gt;% modeltime_forecast( new_data = testing(splits), actual_data = btc_final_df ) %&gt;% plot_modeltime_forecast( .legend_max_width = 10, .title = &quot;Serie con Modelos ARIMA, ETS y Prophet&quot; ) # Reajustar los modelos con todos los datos disponibles refit_tbl &lt;- calibration_tbl %&gt;% modeltime_refit(data = btc_final_df) ## frequency = 7 observations per 1 week ## frequency = 7 observations per 1 week refit_tbl %&gt;% modeltime_forecast(h = &quot;10 days&quot;, actual_data = btc_final_df) %&gt;% plot_modeltime_forecast( .legend_max_width = 25 ) De las predicciones se puede observar que: ARIMA: Línea con un ajuste razonable en la tendencia hacia el final del horizonte histórico. Su predicción (en la zona sombreada) parece ajustarse bien a la tendencia de los últimos valores. ETS: Presenta una predicción más conservadora y estable. Este modelo parece menos reactivo a los cambios recientes en la tendencia. Prophet: Este modelo genera una predicción que parece más sensible a la variabilidad de la serie histórica y, posiblemente, es más optimista hacia el final del horizonte. 6.3 Selección del mejor modelo # Calcular métricas y manejar valores NA calibration_tbl %&gt;% modeltime_accuracy() %&gt;% as.data.frame() %&gt;% replace(is.na(.), 0) ## .model_id .model_desc .type mae mape mase smape rmse ## 1 1 ARIMA(2,1,2)(2,0,2)[7] Test 10305.31 13.19239 7.606466 15.04575 15394.89 ## 2 2 ETS(M,AD,N) Test 10388.92 13.31191 7.668180 15.18835 15467.39 ## 3 3 PROPHET Test 14221.04 22.43294 10.496710 19.58247 16135.34 ## rsq ## 1 0.004168647 ## 2 0.092593765 ## 3 0.494743781 El modelo ARIMA muestra: MAE: Similar al ETS. MAPE: Muy competitivo, siendo similar al del ETS. RMSE: Similar al de ETS. R²: Demasiado bajo, muestra poca capacidad de explicar la variación de los datos. El modelo ETS muestra: MAE: Similar al de ARIMA. MAPE: Similar al de ARIMA. RMSE: Similar al de ARIMA. R²: Muy bajo, aunque ligeramente mejor que ARIMA. El modelo PROPHET: muestra peores métricas en general. MAE: Más alto, el peor de todos. MAPE: Mucho mayor, casi el doble que el de los demás. RMSE: Alto, el peor. R²: modearado, el mejor entre los modelos, lo que indica que captura mejor las tendencias generales pero a sacrificando de precisión. En consecuencia, el modelo ETS tiene el mejor equilibrio entre precisión y capacidad explicativa, no obstante, resulta necesatio tener en cuenta la naturaleza de este modelo, que mantiene constante las predicciones. Por tanto, se sugiere utilizar el modelo ARIMA, dado que también presenta métricas competitivas aunque un coeficiente de determinación prácticamente nulo, pero esto es típico en series temporales no estacionarias, donde ARIMA prioriza la precisión en la predicción en lugar de la explicación estadística. Cabe resaltar que para la comparación se partió de la serie original y no la diferenciada. Además, a diferencia de ETS, el modelo ARIMA tiene más flexibilidad para modelar dinámicas complejas, como tendencias, estacionalidad, y comportamientos persistentes, lo que lo hace adecuado para series temporales volátiles o con patrones significativos. "],["redes-neuronales-recurrentes.html", "Capítulo 7 Redes Neuronales Recurrentes 7.1 Elman Neural Networks 7.2 Jordan Neural Networks", " Capítulo 7 Redes Neuronales Recurrentes Consisten en un tipo de arquitectura de redes neuronales diseñadas para procesar datos secuenciales o temporales. Esto las hace particularmente útiles para tareas donde el orden o la temporalidad de los datos importa, como el procesamiento de texto, series temporales, y señales como audio o video. Utilizan el contexto histórico de una serie de tiempo para predecir valores futuros, como en la predicción de tendencias económicas o financieras. 7.1 Elman Neural Networks Son una de las primeras arquitecturas de Redes Neuronales Recurrentes (RNN) y se destacaron por su enfoque innovador al incorporar una memoria explícita a través de las neuronas de contexto. Esta capacidad de memoria les permitió manejar datos secuenciales y modelar relaciones temporales en tareas como predicción de series temporales, reconocimiento de patrones y procesamiento del lenguaje natural. Inicialmente se estandarizan los datos # Escalar los datos y &lt;- as.ts(scale(btc_final)) Los datos de la serie se escalaron para asegurar que todas las variables tengan una media de cero y una desviación estándar de uno, lo que facilita el entrenamiento de la red neuronal. Posteriormente se selecciona la cantidad de rezagos: # Se convierte la serie a la clase zoo y &lt;- as.zoo(y) # Operador Quantmod Lag: x1&lt;-Lag(y,k=1) x2&lt;-Lag(y,k=2) x3&lt;-Lag(y,k=3) x4&lt;-Lag(y,k=4) x5&lt;-Lag(y,k=5) x6&lt;-Lag(y,k=6) x7&lt;-Lag(y,k=7) x8&lt;-Lag(y,k=8) x9&lt;-Lag(y,k=9) x10&lt;-Lag(y,k=10) Se crearon 10 variables de rezago (lags) de la serie temporal, representando los valores anteriores en distintos momentos. Estos rezagos sirven como atributos de entrada para la red, permitiendo que el modelo capture dependencias temporales. # se agrupan las variables rnn_btc_elm &lt;- cbind(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10) rnn_btc_elm &lt;- cbind(y,rnn_btc_elm) # se guarda el vector para la otra red neuronal rnn_btc_jor &lt;- cbind(y,rnn_btc_elm) # se eliminan los NA rnn_btc_elm &lt;- rnn_btc_elm[-(1:10),] # Visualizar rezagos head(round(rnn_btc_elm,2),10) ## y Lag.1 Lag.2 Lag.3 Lag.4 Lag.5 Lag.6 Lag.7 Lag.8 Lag.9 Lag.10 ## 11 -0.34 -0.18 -0.07 -0.04 -0.12 -0.27 -0.44 -0.55 -0.51 -0.54 -0.70 ## 12 -0.44 -0.34 -0.18 -0.07 -0.04 -0.12 -0.27 -0.44 -0.55 -0.51 -0.54 ## 13 -0.24 -0.44 -0.34 -0.18 -0.07 -0.04 -0.12 -0.27 -0.44 -0.55 -0.51 ## 14 -0.13 -0.24 -0.44 -0.34 -0.18 -0.07 -0.04 -0.12 -0.27 -0.44 -0.55 ## 15 -0.27 -0.13 -0.24 -0.44 -0.34 -0.18 -0.07 -0.04 -0.12 -0.27 -0.44 ## 16 -0.31 -0.27 -0.13 -0.24 -0.44 -0.34 -0.18 -0.07 -0.04 -0.12 -0.27 ## 17 -0.33 -0.31 -0.27 -0.13 -0.24 -0.44 -0.34 -0.18 -0.07 -0.04 -0.12 ## 18 -0.28 -0.33 -0.31 -0.27 -0.13 -0.24 -0.44 -0.34 -0.18 -0.07 -0.04 ## 19 -0.31 -0.28 -0.33 -0.31 -0.27 -0.13 -0.24 -0.44 -0.34 -0.18 -0.07 ## 20 -0.34 -0.31 -0.28 -0.33 -0.31 -0.27 -0.13 -0.24 -0.44 -0.34 -0.18 Se crea el set de entrenamiento: # Configurar la semilla para reproducibilidad set.seed(123) # Número total de filas num_filas_elm &lt;- nrow(rnn_btc_elm) # Proporción de entrenamiento (80%) prop_train_elm &lt;- 0.8 num_train_elm &lt;- floor(num_filas_elm * prop_train_elm) # Crear índices para las filas de entrenamiento train_indices_elm &lt;- sample(1:num_filas_elm, size = num_train_elm, replace = FALSE) Se dividió el conjunto de datos en entrenamiento (80%) de manera aleatoria para evaluar el rendimiento del modelo en datos no vistos. Se crea la Red Neuronal Elman y se entrena: # se definen valores de entrada y salida de la red inputs &lt;- rnn_btc_elm[,2:10] outputs &lt;- rnn_btc_elm[,1] fit &lt;- elman( inputs[train_indices_elm], outputs[train_indices_elm], size=c(4,2), learnFuncParams=c(0.1), maxit =5000 ) Las 10 variables de rezago se utilizaron como entradas para la red neuronal. Por otra parte, la serie temporal original se utilizó como la variable objetivo que el modelo intenta predecir. Se implementó una red con dos capas ocultas; la primera con 3 neuronas y la segunda con 2 neuronas. Esta configuración permite al modelo capturar patrones complejos en los datos. La tasa de aprendizaje se estableció en 0.1, determinando la velocidad con la que el modelo ajusta sus pesos durante el entrenamiento. El número de iteraciones se fijó en 5,000, indicando cuántas veces el algoritmo de entrenamiento procesa el conjunto de datos completo. plotIterativeError(fit) Al graficar el error iterativo, se observó una rápida convergencia hacia cero, sugiriendo que el modelo aprendió eficazmente la relación entre las variables de entrada y la salida. Se realiza predicción con los términos restantes de la serie: # Convertir la salida a vector y&lt;-as.vector(outputs[-train_indices_elm]) # Graficar los valores reales con título y etiquetas plot(y, type = &quot;l&quot;, col = &quot;blue&quot;, main = &quot;Predicción con Elman&quot;, xlab = &quot;Índice de Tiempo&quot;, ylab = &quot;Valor y&quot;) # Generar predicciones pred &lt;- predict(fit, inputs[-train_indices_elm]) # Añadir las predicciones al gráfico en rojo lines(pred, col = &quot;red&quot;) # Agregar una leyenda para distinguir entre valores reales y predicciones legend(&quot;topright&quot;, legend = c(&quot;Valores Reales&quot;, &quot;Predicción&quot;), col = c(&quot;blue&quot;, &quot;red&quot;), lty = 1, cex = 0.7) # Métricas de las series cat(&quot;Coeficiente de correlación&quot;, cor(outputs[-train_indices_elm], pred)^2, &quot;\\n&quot;) ## Coeficiente de correlación 0.9853925 cat(&quot;Error cuadrático medio&quot;, mean((outputs[-train_indices_elm] - pred)^2), &quot;\\n&quot;) ## Error cuadrático medio 0.04617113 Se realizaron predicciones sobre el conjunto de prueba para evaluar la capacidad del modelo en datos no vistos. Se observa que la predicción sobre la serie original es buena, en muchas ocasiones coincide con los datos reales. Este proceso demuestra una aplicación meticulosa de las Redes Neuronales Elman en la modelación de series temporales, destacando la importancia del preprocesamiento de datos, la adecuada parametrización del modelo y la evaluación rigurosa para asegurar un rendimiento óptimo. 7.2 Jordan Neural Networks Son otra variante de las Redes Neuronales Recurrentes (RNN). Estas redes son similares a las Redes de Elman, pero presentan una diferencia clave: en lugar de usar la salida de la capa oculta para las conexiones de contexto, las Redes de Jordan utilizan la salida de la red como memoria recurrente. Para hacer lo más posible comparable a la red Jordan con la red Elman, se aplican los mismos pasos. Se crea el set de entrenamiento: # se eliminan los NA rnn_btc_jor &lt;- rnn_btc_jor[-(1:10),] # Configurar la semilla para reproducibilidad set.seed(123) # Número total de filas num_filas_jor &lt;- nrow(rnn_btc_jor) # Proporción de entrenamiento (80%) prop_train_jor &lt;- 0.8 num_train_jor &lt;- floor(num_filas_jor * prop_train_jor) # Crear índices para las filas de entrenamiento train_indices_jor &lt;- sample(1:num_filas_jor, size = num_train_jor, replace = FALSE) Se crea la Red Neuronal Jordan y se entrena: # se definen valores de entrada y salida de la red inputs2 &lt;- rnn_btc_jor[,2:10] outputs2 &lt;- rnn_btc_jor[,1] fit2 &lt;- jordan( inputs2[train_indices_jor], outputs2[train_indices_jor], size=4, learnFuncParams=c(0.1), maxit =5000 ) Se han solicitado cuatro capas ocultas y un factor de tasa de aprendizaje de 0.1. plotIterativeError(fit2) Se observa que el error también converge muy rápidamente hacia cero. Se realiza predicción con los términos restantes de la serie: # Convertir la salida a vector y&lt;-as.vector(outputs2[-train_indices_jor]) # Graficar los valores reales con título y etiquetas plot(y, type = &quot;l&quot;, col = &quot;blue&quot;, main = &quot;Predicción con Jordan&quot;, xlab = &quot;Índice de Tiempo&quot;, ylab = &quot;Valor y&quot;) # Generar predicciones pred2 &lt;- predict(fit2, inputs2[-train_indices_jor]) # Añadir las predicciones al gráfico en rojo lines(pred2, col = &quot;red&quot;) # Agregar una leyenda para distinguir entre valores reales y predicciones legend(&quot;topright&quot;, legend = c(&quot;Valores Reales&quot;, &quot;Predicción&quot;), col = c(&quot;blue&quot;, &quot;red&quot;), lty = 1, cex = 0.7) # Métricas de las series cat(&quot;Coeficiente de correlación&quot;, cor(outputs2[-train_indices_jor], pred2)^2, &quot;\\n&quot;) ## Coeficiente de correlación 0.9984554 cat(&quot;Error cuadrático medio&quot;, mean((outputs2[-train_indices_jor] - pred2)^2), &quot;\\n&quot;) ## Error cuadrático medio 0.001466731 Se observa que la predicción sobre la serie original en este caso también es buena, incluso un poco mejor que la predicción con Elman, lo que se soporta con un mayor coeficiente de correlación y un menor error cuadrático medio, sin embargo, esto puede deberse a diferencias en los hiperparámetros utilizados; los hiperparámetros como el tamaño de las capas ocultas, la tasa de aprendizaje y el número de iteracciones han sido más adecuados para el modelo de Jordan en este caso específico. Adicional, las redes Jordan, al utilizar la salida como contexto recurrente, pueden captar patrones diferentes en los datos, lo que podría darles una ventaja en ciertas configuraciones. "],["conclusiones.html", "Capítulo 8 Conclusiones", " Capítulo 8 Conclusiones En este documento, se realizó un análisis del comportamiento del precio del Bitcoin utilizando diversas herramientas y metodologías para series de tiempo. Se evidenció que estas permiten comprender patrones históricos, modelar la volatilidad y realizar pronósticos. El precio del Bitcoin presenta características únicas en comparación con otros activos financieros, como una alta volatilidad y fluctuaciones impredecibles influenciadas por factores externos como regulaciones, adopción institucional, especulación, sentimiento del mercado, entre otros. Esto plantea desafíos para los modelos tradicionales de series de tiempo, destacando la necesidad de metodologías avanzadas y adaptativas para capturar estos patrones y realizar pronósticos precisos. Se evidencia que ningún modelo es suficiente por sí solo para capturar completamente la dinámica del precio del Bitcoin. Los modelos ARIMA son útiles para identificar patrones lineales, mientras que enfoques como Prophet y las redes neuronales recurrentes destacan al manejar tendencias no lineales y complejidades. La integración de modelos tradicionales con técnicas modernas proporciona un enfoque más robusto y versátil para abordar la incertidumbre del mercado. El éxito del análisis depende de un preprocesamiento adecuado, como la diferenciación para estacionarizar la serie y la descomposición para entender componentes subyacentes; tendencia, estacionalidad y ruido. Además, la comparación mediante métricas como MAE, RMSE, AIC, BIC, entre otras, asegura que los modelos seleccionados sean óptimos para los datos y objetivos específicos. Este enfoque meticuloso garantiza pronósticos más confiables y decisiones basadas en evidencia. "]]
